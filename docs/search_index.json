[
["comparison.html", "Manual Data Science Tools Chapter 1 Comparison", " Manual Data Science Tools Łukasz Muszyński 2019-09-16 Chapter 1 Comparison Scikit-Learn vs mlr "],
["intro.html", "Chapter 2 INTRO", " Chapter 2 INTRO "],
["python-keras.html", "Chapter 3 Python_Keras", " Chapter 3 Python_Keras "],
["python-pytorch.html", "Chapter 4 Python_PyTorch", " Chapter 4 Python_PyTorch "],
["scikit-learn.html", "Chapter 5 Scikit-Learn 5.1 Problem ze zwracaniem prawdopodobienstw w Grid Search:", " Chapter 5 Scikit-Learn 5.1 Problem ze zwracaniem prawdopodobienstw w Grid Search: Zobaczyć w https://scikit-learn.org/stable/modules/model_evaluation.html#scoring . Wyszukać fraze “needs_threshold=True” . import pandas as pd import sklearn as sk import numpy as np from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import RandomizedSearchCV from scipy.stats import randint as sp_randint from sklearn.metrics import fbeta_score, make_scorer, precision_score, f1_score Przygotowanie zbioru danych w R require(ggplot2) df &lt;- diamonds data = r.df df = data.head(200) np.min(df.price) # stworzenie sztnucznych zmiennych kategorycznych dla potrzeb modelu df[&#39;categorical_2_cat&#39;] = list(np.random.choice([0,1], 200)) # 2 kategorie df[&#39;categorical_3_cat&#39;] = list(np.random.choice([0,1,2], 200)) # 3 kategorie # wlasne funkcja scorowa def moje_scory(y, y_pred, threshold = [0.3], parameter = &#39;precision&#39;): # determining decision of the model based on provided threshold y_score = np.array([ 0 if x &lt; threshold else 1 for x in y_pred]) if parameter == &#39;precision&#39;: result = precision_score(y, y_score) if parameter == &#39;f1_score&#39;: result = f1_score(y, y_score) return(result) # parametry do tunningu param = {&quot;max_depth&quot;: [3, None] # , &quot;max_features&quot;: sp_randint(1, 11) , &quot;min_samples_split&quot;: sp_randint(2, 11) , &quot;bootstrap&quot;: [True, False] , &quot;criterion&quot;: [&quot;gini&quot;, &quot;entropy&quot;]} # okreslenie modelu model = RandomForestClassifier(n_estimators=20) # ilosc iteracji n_iter_search = 10 random_search = RandomizedSearchCV( model , param_distributions = param , n_iter = n_iter_search , cv = 5 # po walidacji krzyzowej beda liczone mean i std dla scorow. Dlatego np. str bedzie policzone nawet jezeli Grid search ma jedna iteracje. , scoring = { &#39;precision_03&#39;:make_scorer(moje_scory, needs_proba = True, threshold = [0.3], parameter = &#39;precision&#39;) ,&#39;f1_score_05&#39;:make_scorer(moje_scory, needs_proba = True, threshold = [0.5], parameter = &#39;f1_score&#39;) } , refit = False) # jezeli do scoingu jest przekazywanych kilka funkcji musimy dac refit = False # wykonanie przeszukania siatki result = random_search.fit(X=df[[&#39;x&#39;,&#39;y&#39;,&#39;z&#39;,&#39;table&#39;]], y=df[&#39;categorical_2_cat&#39;]) result.cv_results_ # szczelowe wyniki grid-a w postaci slownika result.cv_results_.keys() # lista klczy slownika dla ulatwienia wyszkania interesujacych nas informacji # poszczegolne wyniki scorow result.cv_results_[&#39;mean_train_precision_03&#39;] result.cv_results_[&#39;mean_train_f1_score_05&#39;] result.cv_results_[&#39;std_train_precision_03&#39;] result.cv_results_[&#39;std_train_f1_score_05&#39;] "],
["python-statmodels.html", "Chapter 6 Python_Statmodels", " Chapter 6 Python_Statmodels "],
["python-tensofflow.html", "Chapter 7 Python_TensofFlow", " Chapter 7 Python_TensofFlow "],
["r-mlr.html", "Chapter 8 R_MLR", " Chapter 8 R_MLR "],
["chapter.html", "Chapter 9 chapter", " Chapter 9 chapter "]
]
